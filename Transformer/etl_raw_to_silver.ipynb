{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc9aea16",
   "metadata": {},
   "source": [
    "# ETL Raw para Silver - Movies Dataset\n",
    "\n",
    "Este notebook executa o ETL da camada Raw para a camada Silver do projeto.\n",
    "\n",
    "Etapas:\n",
    "- Extract: leitura do CSV bruto\n",
    "- Transform: limpeza, padronizacao, enriquecimento e validacao\n",
    "- Load: gravacao na camada Silver (CSV) e opcionalmente no PostgreSQL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79461f53",
   "metadata": {},
   "source": [
    "## 1. Importacoes e configuracao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0673093e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1ca5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_colwidth\", 120)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59b88a6",
   "metadata": {},
   "source": [
    "### 1.1 Caminhos do projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e30720b",
   "metadata": {},
   "outputs": [],
   "source": [
    "CWD = Path.cwd()\n",
    "PROJECT_ROOT = None\n",
    "\n",
    "for candidate in [CWD, *CWD.parents]:\n",
    "    if (candidate / \"Data Layer\").exists() and (candidate / \"base de dados.csv\").exists():\n",
    "        PROJECT_ROOT = candidate\n",
    "        break\n",
    "\n",
    "if PROJECT_ROOT is None:\n",
    "    raise FileNotFoundError(\n",
    "        f\"Nao encontrei a pasta do projeto a partir de {CWD}. \"\n",
    "        \"Verifique se o notebook esta dentro do repositorio.\"\n",
    "    )\n",
    "\n",
    "RAW_FILE = PROJECT_ROOT / \"base de dados.csv\"\n",
    "SILVER_DIR = PROJECT_ROOT / \"Data Layer\" / \"silver\"\n",
    "SILVER_FILE = SILVER_DIR / \"movies_silver.csv\"\n",
    "SILVER_PARQUET = SILVER_DIR / \"movies_silver.parquet\"\n",
    "\n",
    "print(f\"Projeto: {PROJECT_ROOT}\")\n",
    "print(f\"Raw: {RAW_FILE}\")\n",
    "print(f\"Silver: {SILVER_FILE}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57281e5a",
   "metadata": {},
   "source": [
    "### 1.2 Conexao com banco (opcional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb60b75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ative apenas se quiser carregar no PostgreSQL\n",
    "LOAD_TO_DB = False\n",
    "\n",
    "DB_HOST = os.getenv(\"DB_HOST\", \"localhost\")\n",
    "DB_PORT = os.getenv(\"DB_PORT\", \"5432\")\n",
    "DB_NAME = os.getenv(\"DB_NAME\", \"movies_dw\")\n",
    "DB_USER = os.getenv(\"DB_USER\", \"postgres\")\n",
    "DB_PASSWORD = os.getenv(\"DB_PASSWORD\", \"postgres\")\n",
    "\n",
    "CONNECTION_STRING = f\"postgresql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}\"\n",
    "\n",
    "try:\n",
    "    from sqlalchemy import create_engine, text\n",
    "    HAS_SQLALCHEMY = True\n",
    "except Exception:\n",
    "    HAS_SQLALCHEMY = False\n",
    "\n",
    "engine = None\n",
    "if LOAD_TO_DB and HAS_SQLALCHEMY:\n",
    "    engine = create_engine(CONNECTION_STRING, pool_size=5, max_overflow=10)\n",
    "    print(\"Conexao PostgreSQL pronta\")\n",
    "elif LOAD_TO_DB:\n",
    "    print(\"SQLAlchemy nao instalado. Desative LOAD_TO_DB ou instale a dependencia.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebcade0",
   "metadata": {},
   "source": [
    "## 2. Extract - leitura dos dados brutos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccb6eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Carregando CSV bruto...\")\n",
    "df_raw = pd.read_csv(RAW_FILE, low_memory=False)\n",
    "\n",
    "print(f\"Linhas: {len(df_raw):,}\")\n",
    "print(f\"Colunas: {len(df_raw.columns)}\")\n",
    "print(f\"Memoria: {df_raw.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "\n",
    "print(\"Amostra:\")\n",
    "display(df_raw.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ff5811",
   "metadata": {},
   "source": [
    "## 3. Transform - limpeza e enriquecimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8e31e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(series: pd.Series) -> pd.Series:\n",
    "    # Padroniza strings e converte vazios para NA\n",
    "    s = series.astype(\"string\").str.strip()\n",
    "    s = s.replace({\"\": pd.NA, \"None\": pd.NA, \"nan\": pd.NA, \"NaN\": pd.NA})\n",
    "    return s\n",
    "\n",
    "\n",
    "def clean_csv_list(value: str):\n",
    "    # Limpa campos CSV (separados por virgula)\n",
    "    if pd.isna(value):\n",
    "        return pd.NA\n",
    "    parts = [p.strip() for p in str(value).split(\",\")]\n",
    "    parts = [p for p in parts if p and p.lower() not in {\"nan\", \"none\"}]\n",
    "    if not parts:\n",
    "        return pd.NA\n",
    "    seen = set()\n",
    "    dedup = []\n",
    "    for p in parts:\n",
    "        if p not in seen:\n",
    "            dedup.append(p)\n",
    "            seen.add(p)\n",
    "    return \", \".join(dedup)\n",
    "\n",
    "\n",
    "def normalize_imdb_id(value: str):\n",
    "    if pd.isna(value):\n",
    "        return pd.NA\n",
    "    v = str(value).strip()\n",
    "    if v == \"\":\n",
    "        return pd.NA\n",
    "    if not v.startswith(\"tt\"):\n",
    "        return pd.NA\n",
    "    return v if len(v) <= 12 else v[:12]\n",
    "\n",
    "\n",
    "def parse_bool(value):\n",
    "    if pd.isna(value):\n",
    "        return pd.NA\n",
    "    v = str(value).strip().lower()\n",
    "    if v in {\"true\", \"t\", \"1\", \"yes\"}:\n",
    "        return True\n",
    "    if v in {\"false\", \"f\", \"0\", \"no\"}:\n",
    "        return False\n",
    "    return pd.NA\n",
    "\n",
    "\n",
    "def cinema_era(year):\n",
    "    if pd.isna(year):\n",
    "        return pd.NA\n",
    "    y = int(year)\n",
    "    if y < 1930:\n",
    "        return \"Cinema mudo\"\n",
    "    if y < 1960:\n",
    "        return \"Era dourada\"\n",
    "    if y < 1980:\n",
    "        return \"Nova Hollywood\"\n",
    "    if y < 2000:\n",
    "        return \"Blockbuster\"\n",
    "    if y < 2010:\n",
    "        return \"Digital\"\n",
    "    return \"Streaming\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c00b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_raw.copy()\n",
    "\n",
    "text_cols = [\n",
    "    \"title\",\n",
    "    \"status\",\n",
    "    \"original_language\",\n",
    "    \"original_title\",\n",
    "    \"overview\",\n",
    "    \"tagline\",\n",
    "    \"genres\",\n",
    "    \"production_companies\",\n",
    "    \"production_countries\",\n",
    "    \"spoken_languages\",\n",
    "    \"keywords\",\n",
    "    \"homepage\",\n",
    "    \"imdb_id\",\n",
    "    \"poster_path\",\n",
    "    \"backdrop_path\",\n",
    "]\n",
    "\n",
    "for col in text_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = normalize_text(df[col])\n",
    "\n",
    "# Normaliza imdb_id\n",
    "if \"imdb_id\" in df.columns:\n",
    "    df[\"imdb_id\"] = df[\"imdb_id\"].apply(normalize_imdb_id)\n",
    "\n",
    "# Normaliza idioma\n",
    "if \"original_language\" in df.columns:\n",
    "    df[\"original_language\"] = df[\"original_language\"].str.lower()\n",
    "    df.loc[df[\"original_language\"].str.len() != 2, \"original_language\"] = pd.NA\n",
    "\n",
    "# Normaliza adult\n",
    "if \"adult\" in df.columns:\n",
    "    df[\"adult\"] = df[\"adult\"].apply(parse_bool)\n",
    "\n",
    "# Conversao de tipos numericos\n",
    "num_cols = [\"id\", \"vote_average\", \"vote_count\", \"revenue\", \"budget\", \"runtime\", \"popularity\"]\n",
    "for col in num_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "if \"id\" in df.columns:\n",
    "    df[\"id\"] = df[\"id\"].astype(\"Int64\")\n",
    "if \"vote_count\" in df.columns:\n",
    "    df[\"vote_count\"] = df[\"vote_count\"].astype(\"Int64\")\n",
    "if \"runtime\" in df.columns:\n",
    "    df[\"runtime\"] = df[\"runtime\"].astype(\"Int64\")\n",
    "\n",
    "# Limpeza de valores invalidos\n",
    "if \"vote_average\" in df.columns:\n",
    "    df.loc[(df[\"vote_average\"] < 0) | (df[\"vote_average\"] > 10), \"vote_average\"] = pd.NA\n",
    "if \"vote_count\" in df.columns:\n",
    "    df.loc[df[\"vote_count\"] < 0, \"vote_count\"] = pd.NA\n",
    "if \"revenue\" in df.columns:\n",
    "    df.loc[df[\"revenue\"] < 0, \"revenue\"] = pd.NA\n",
    "if \"budget\" in df.columns:\n",
    "    df.loc[df[\"budget\"] < 0, \"budget\"] = pd.NA\n",
    "if \"runtime\" in df.columns:\n",
    "    df.loc[(df[\"runtime\"] <= 0) | (df[\"runtime\"] > 600), \"runtime\"] = pd.NA\n",
    "if \"popularity\" in df.columns:\n",
    "    df.loc[df[\"popularity\"] < 0, \"popularity\"] = pd.NA\n",
    "\n",
    "# Datas\n",
    "if \"release_date\" in df.columns:\n",
    "    df[\"release_date\"] = pd.to_datetime(df[\"release_date\"], errors=\"coerce\")\n",
    "    df[\"year\"] = df[\"release_date\"].dt.year.astype(\"Int64\")\n",
    "    df[\"month\"] = df[\"release_date\"].dt.month.astype(\"Int64\")\n",
    "    df[\"day\"] = df[\"release_date\"].dt.day.astype(\"Int64\")\n",
    "    df[\"day_of_week\"] = df[\"release_date\"].dt.dayofweek.astype(\"Int64\")\n",
    "    df[\"quarter\"] = df[\"release_date\"].dt.quarter.astype(\"Int64\")\n",
    "    df[\"week_of_year\"] = df[\"release_date\"].dt.isocalendar().week.astype(\"Int64\")\n",
    "    df[\"decade\"] = (df[\"year\"] // 10 * 10).astype(\"Int64\")\n",
    "    df[\"is_weekend\"] = df[\"day_of_week\"].isin([5, 6])\n",
    "    df[\"cinema_era\"] = df[\"year\"].apply(cinema_era).astype(\"string\")\n",
    "\n",
    "# Campos CSV\n",
    "list_cols = [\"genres\", \"production_companies\", \"production_countries\", \"spoken_languages\", \"keywords\"]\n",
    "for col in list_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].apply(clean_csv_list).astype(\"string\")\n",
    "\n",
    "# Metricas derivadas\n",
    "if \"revenue\" in df.columns and \"budget\" in df.columns:\n",
    "    df[\"profit\"] = df[\"revenue\"] - df[\"budget\"]\n",
    "    df[\"roi\"] = np.where(\n",
    "        df[\"budget\"] > 0,\n",
    "        (df[\"revenue\"] - df[\"budget\"]) / df[\"budget\"] * 100,\n",
    "        np.nan,\n",
    "    )\n",
    "\n",
    "if \"vote_average\" in df.columns and \"vote_count\" in df.columns:\n",
    "    df[\"engagement\"] = df[\"vote_average\"] * np.log1p(df[\"vote_count\"])\n",
    "\n",
    "if \"revenue\" in df.columns and \"runtime\" in df.columns:\n",
    "    df[\"revenue_per_minute\"] = np.where(df[\"runtime\"] > 0, df[\"revenue\"] / df[\"runtime\"], np.nan)\n",
    "\n",
    "if \"vote_average\" in df.columns and \"vote_count\" in df.columns:\n",
    "    quality_raw = (df[\"vote_average\"].fillna(0) * np.log1p(df[\"vote_count\"].fillna(0)))\n",
    "    q_min = quality_raw.min()\n",
    "    q_max = quality_raw.max()\n",
    "    if pd.notna(q_min) and pd.notna(q_max) and q_max != q_min:\n",
    "        df[\"quality_score\"] = (quality_raw - q_min) / (q_max - q_min) * 100\n",
    "    else:\n",
    "        df[\"quality_score\"] = pd.NA\n",
    "\n",
    "# Faixas\n",
    "if \"revenue\" in df.columns:\n",
    "    df[\"revenue_range\"] = pd.cut(\n",
    "        df[\"revenue\"],\n",
    "        bins=[-1, 0, 1e6, 1e7, 5e7, 1e8, 5e8, np.inf],\n",
    "        labels=[\"Zero\", \"<1M\", \"1-10M\", \"10-50M\", \"50-100M\", \"100-500M\", \">500M\"],\n",
    "    ).astype(\"string\")\n",
    "\n",
    "if \"budget\" in df.columns:\n",
    "    df[\"budget_range\"] = pd.cut(\n",
    "        df[\"budget\"],\n",
    "        bins=[-1, 0, 1e6, 1e7, 5e7, 1e8, 2.5e8, np.inf],\n",
    "        labels=[\"Zero\", \"<1M\", \"1-10M\", \"10-50M\", \"50-100M\", \"100-250M\", \">250M\"],\n",
    "    ).astype(\"string\")\n",
    "\n",
    "if \"vote_average\" in df.columns:\n",
    "    df[\"rating_range\"] = pd.cut(\n",
    "        df[\"vote_average\"],\n",
    "        bins=[-0.1, 4, 6, 7, 8, 10],\n",
    "        labels=[\"Ruim\", \"Regular\", \"Bom\", \"Muito bom\", \"Excelente\"],\n",
    "    ).astype(\"string\")\n",
    "\n",
    "if \"runtime\" in df.columns:\n",
    "    df[\"runtime_range\"] = pd.cut(\n",
    "        df[\"runtime\"],\n",
    "        bins=[-1, 60, 90, 120, 150, np.inf],\n",
    "        labels=[\"<60\", \"60-90\", \"90-120\", \"120-150\", \">150\"],\n",
    "    ).astype(\"string\")\n",
    "\n",
    "if \"popularity\" in df.columns:\n",
    "    df[\"popularity_range\"] = pd.cut(\n",
    "        df[\"popularity\"],\n",
    "        bins=[-1, 1, 5, 10, 20, 50, np.inf],\n",
    "        labels=[\"<1\", \"1-5\", \"5-10\", \"10-20\", \"20-50\", \">50\"],\n",
    "    ).astype(\"string\")\n",
    "\n",
    "# Deduplicacao por id\n",
    "if \"id\" in df.columns:\n",
    "    df = df.dropna(subset=[\"id\"])\n",
    "    df = df.sort_values(by=[\"id\", \"vote_count\", \"revenue\", \"budget\"], ascending=[True, False, False, False])\n",
    "    df = df.drop_duplicates(subset=[\"id\"], keep=\"first\")\n",
    "\n",
    "# Metadados\n",
    "df[\"load_timestamp\"] = pd.Timestamp.now()\n",
    "df[\"source\"] = \"base de dados.csv\"\n",
    "\n",
    "print(f\"Linhas finais: {len(df):,}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d0332e",
   "metadata": {},
   "source": [
    "### 3.1 Reordenacao das colunas (padrao Silver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1b9355",
   "metadata": {},
   "outputs": [],
   "source": [
    "silver_columns = [\n",
    "    \"id\",\n",
    "    \"title\",\n",
    "    \"original_title\",\n",
    "    \"imdb_id\",\n",
    "    \"overview\",\n",
    "    \"tagline\",\n",
    "    \"status\",\n",
    "    \"adult\",\n",
    "    \"original_language\",\n",
    "    \"release_date\",\n",
    "    \"year\",\n",
    "    \"month\",\n",
    "    \"day\",\n",
    "    \"day_of_week\",\n",
    "    \"quarter\",\n",
    "    \"week_of_year\",\n",
    "    \"decade\",\n",
    "    \"cinema_era\",\n",
    "    \"is_weekend\",\n",
    "    \"vote_average\",\n",
    "    \"vote_count\",\n",
    "    \"popularity\",\n",
    "    \"revenue\",\n",
    "    \"budget\",\n",
    "    \"profit\",\n",
    "    \"roi\",\n",
    "    \"runtime\",\n",
    "    \"engagement\",\n",
    "    \"revenue_per_minute\",\n",
    "    \"quality_score\",\n",
    "    \"revenue_range\",\n",
    "    \"budget_range\",\n",
    "    \"rating_range\",\n",
    "    \"runtime_range\",\n",
    "    \"popularity_range\",\n",
    "    \"genres\",\n",
    "    \"production_companies\",\n",
    "    \"production_countries\",\n",
    "    \"spoken_languages\",\n",
    "    \"keywords\",\n",
    "    \"homepage\",\n",
    "    \"poster_path\",\n",
    "    \"backdrop_path\",\n",
    "    \"load_timestamp\",\n",
    "    \"source\",\n",
    "]\n",
    "\n",
    "available_cols = [c for c in silver_columns if c in df.columns]\n",
    "df_silver = df[available_cols].copy()\n",
    "\n",
    "print(f\"Colunas Silver: {len(df_silver.columns)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f45c33e",
   "metadata": {},
   "source": [
    "## 4. Load - gravacao na camada Silver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565c694c",
   "metadata": {},
   "outputs": [],
   "source": [
    "SILVER_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Salvando CSV da camada Silver...\")\n",
    "df_silver.to_csv(SILVER_FILE, index=False, encoding=\"utf-8\")\n",
    "print(f\"Arquivo salvo: {SILVER_FILE}\")\n",
    "\n",
    "# Salvar Parquet (opcional)\n",
    "try:\n",
    "    df_silver.to_parquet(SILVER_PARQUET, index=False)\n",
    "    print(f\"Arquivo salvo: {SILVER_PARQUET}\")\n",
    "except Exception:\n",
    "    print(\"Parquet nao gerado (instale pyarrow ou fastparquet se desejar).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a932c68",
   "metadata": {},
   "source": [
    "### 4.1 Carga no PostgreSQL (opcional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f50857",
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOAD_TO_DB and engine is not None:\n",
    "    print(\"Carregando dados no PostgreSQL...\")\n",
    "    with engine.connect() as conn:\n",
    "        conn.execute(text(\"CREATE SCHEMA IF NOT EXISTS silver\"))\n",
    "    df_silver.to_sql(\n",
    "        \"movies\",\n",
    "        engine,\n",
    "        schema=\"silver\",\n",
    "        if_exists=\"replace\",\n",
    "        index=False,\n",
    "        method=\"multi\",\n",
    "        chunksize=2000,\n",
    "    )\n",
    "    print(\"Carga concluida.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9529b979",
   "metadata": {},
   "source": [
    "## 5. Resumo final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca01524c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ETL Raw para Silver concluido.\")\n",
    "print(f\"Registros finais: {len(df_silver):,}\")\n",
    "print(f\"Arquivo: {SILVER_FILE}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
